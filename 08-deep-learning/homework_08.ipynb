{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2f8588",
   "metadata": {},
   "source": [
    "Dataset\n",
    "In this homework, we'll build a model for classifying various hair types. For this, we will use the Hair Type dataset that was obtained from Kaggle and slightly rebuilt.\n",
    "\n",
    "You can download the target dataset for this homework from here:\n",
    "\n",
    "wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "unzip data.zip\n",
    "The dataset is split into train and test dataset. Use train dataset to train the model and test dataset for validation.\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch.\n",
    "\n",
    "We will use PyTorch for that.\n",
    "\n",
    "You can use Google Colab or your own computer for that.\n",
    "\n",
    "Data Preparation\n",
    "The dataset contains around 1000 images of hairs in the separate folders for training and test sets.\n",
    "\n",
    "Reproducibility\n",
    "Reproducibility in deep learning is a multifaceted challenge that requires attention to both software and hardware details. In some cases, we can't guarantee exactly the same results during the same experiment runs.\n",
    "\n",
    "Therefore, in this homework we suggest to set the random number seed generators by:\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "Also, use PyTorch of version 2.8.0 (that's the one in Colab).\n",
    "\n",
    "Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "The shape for input should be (3, 200, 200) (channels first format in PyTorch)\n",
    "Next, create a convolutional layer (nn.Conv2d):\n",
    "Use 32 filters (output channels)\n",
    "Kernel size should be (3, 3) (that's the size of the filter), padding = 0, stride = 1\n",
    "Use 'relu' as activation\n",
    "Reduce the size of the feature map with max pooling (nn.MaxPool2d)\n",
    "Set the pooling size to (2, 2)\n",
    "Turn the multi-dimensional result into vectors using flatten or view\n",
    "Next, add a nn.Linear layer with 64 neurons and 'relu' activation\n",
    "Finally, create the nn.Linear layer with 1 neuron - this will be the output\n",
    "The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "As optimizer use torch.optim.SGD with the following parameters:\n",
    "\n",
    "torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "Question 1\n",
    "Which loss function you will use?\n",
    "\n",
    "nn.MSELoss()\n",
    "nn.BCEWithLogitsLoss()\n",
    "nn.CrossEntropyLoss()\n",
    "nn.CosineEmbeddingLoss()\n",
    "(Multiple answered can be correct, so pick any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecdb2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.3.1)\n",
      "Collecting torch==2.9.1 (from torchvision)\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.1->torchvision)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch==2.9.1->torchvision)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:21\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m  \u001b[33m0:00:14\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:15\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.28.7━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.28.7:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.28.7━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cusolver-cu12]2]2]\n",
      "\u001b[2K    Found existing installation: torch 2.7.1+cpu[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.1+cpu:━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1+cpum\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 torch-2.9.1 torchvision-0.24.1 triton-3.5.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1748407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4d4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0a9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-08 21:15:40--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-08T22%3A12%3A34Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-08T21%3A11%3A55Z&ske=2025-12-08T22%3A12%3A34Z&sks=b&skv=2018-11-09&sig=zzFAHV1AN70llkBv1lLQhJHNKdFZiC8mszGB%2BkGmlig%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTIzMDM0MCwibmJmIjoxNzY1MjI4NTQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.fboGvTE98JirSOAEwiCQ64UuzJwaWbLYjZfVYZHmylY&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-12-08 21:15:40--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-08T22%3A12%3A34Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-08T21%3A11%3A55Z&ske=2025-12-08T22%3A12%3A34Z&sks=b&skv=2018-11-09&sig=zzFAHV1AN70llkBv1lLQhJHNKdFZiC8mszGB%2BkGmlig%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NTIzMDM0MCwibmJmIjoxNzY1MjI4NTQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.fboGvTE98JirSOAEwiCQ64UuzJwaWbLYjZfVYZHmylY&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102516572 (98M) [application/octet-stream]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  97.77M   162MB/s    in 0.6s    \n",
      "\n",
      "2025-12-08 21:15:41 (162 MB/s) - ‘data.zip’ saved [102516572/102516572]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "!unzip -q data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d48e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e510dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curly  straight\n"
     ]
    }
   ],
   "source": [
    "!ls data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765a0ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curly  straight\n"
     ]
    }
   ],
   "source": [
    "!ls data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175f7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13854812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 201)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(\"data/test\", transform=test_transforms)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len(train_dataset), len(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ffd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HairCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv2D\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "\n",
    "        # MaxPooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully Connected\n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  # salida binaria (logit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)  # NO sigmoid acá\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba893d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HairCNN().to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f4767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.002,\n",
    "    momentum=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc6c40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 201)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792878be",
   "metadata": {},
   "source": [
    "Question 2\n",
    "What's the total number of parameters of the model? You can use torchsummary or count manually.\n",
    "\n",
    "In PyTorch, you can find the total number of parameters using:\n",
    "\n",
    "# Option 1: Using torchsummary (install with: pip install torchsummary)\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 200, 200))\n",
    "\n",
    "# Option 2: Manual counting\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "896\n",
    "11214912\n",
    "15896912\n",
    "20073473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1abfd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20073473"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfc401",
   "metadata": {},
   "source": [
    "Generators and Training\n",
    "For the next two questions, use the following transformation for both train and test sets:\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "Use batch_size=20\n",
    "Use shuffle=True for both training, but False for test.\n",
    "Now fit the model.\n",
    "\n",
    "You can use this code:\n",
    "\n",
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\"))\n",
    "Question 3\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "0.05\n",
    "0.12\n",
    "0.40\n",
    "0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7e7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6462, Acc: 0.6362, Val Loss: 0.6032, Val Acc: 0.6517\n",
      "Epoch 2/10, Loss: 0.5475, Acc: 0.7100, Val Loss: 0.7251, Val Acc: 0.6318\n",
      "Epoch 3/10, Loss: 0.5533, Acc: 0.7250, Val Loss: 0.5991, Val Acc: 0.6716\n",
      "Epoch 4/10, Loss: 0.4802, Acc: 0.7712, Val Loss: 0.6033, Val Acc: 0.6567\n",
      "Epoch 5/10, Loss: 0.4334, Acc: 0.8025, Val Loss: 0.6196, Val Acc: 0.6766\n",
      "Epoch 6/10, Loss: 0.3740, Acc: 0.8325, Val Loss: 0.7371, Val Acc: 0.6766\n",
      "Epoch 7/10, Loss: 0.2721, Acc: 0.8838, Val Loss: 0.9223, Val Acc: 0.6418\n",
      "Epoch 8/10, Loss: 0.2478, Acc: 0.9000, Val Loss: 0.7294, Val Acc: 0.7214\n",
      "Epoch 9/10, Loss: 0.2075, Acc: 0.9200, Val Loss: 0.7523, Val Acc: 0.7015\n",
      "Epoch 10/10, Loss: 0.1494, Acc: 0.9450, Val Loss: 0.7894, Val Acc: 0.7015\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)  # labels shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "       \n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # VALIDACIÓN\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "        f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981c9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8116e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8175)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accs = np.array(history['acc'])\n",
    "median_acc = np.median(train_accs)\n",
    "median_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d56728",
   "metadata": {},
   "source": [
    "Question 4\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "0.007\n",
    "0.078\n",
    "0.171\n",
    "1.710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "513ca3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.15896371677643137)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses = np.array(history['loss'])\n",
    "std_loss = np.std(train_losses)\n",
    "std_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b593223",
   "metadata": {},
   "source": [
    "Data Augmentation\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "transforms.RandomRotation(50),\n",
    "transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "transforms.RandomHorizontalFlip(),\n",
    "Question 5\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "Note: make sure you don't re-create the model. we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "0.008\n",
    "0.08\n",
    "0.88\n",
    "8.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8502144",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9ea7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_aug = datasets.ImageFolder(\"data/train\", transform=augmented_train_transforms)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "len(train_dataset_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c921ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7418, Acc: 0.6275, Val Loss: 0.6577, Val Acc: 0.6816\n",
      "Epoch 2/10, Loss: 0.5797, Acc: 0.6837, Val Loss: 0.7310, Val Acc: 0.6766\n",
      "Epoch 3/10, Loss: 0.5754, Acc: 0.7063, Val Loss: 0.5767, Val Acc: 0.6965\n",
      "Epoch 4/10, Loss: 0.5522, Acc: 0.7238, Val Loss: 0.5689, Val Acc: 0.7015\n",
      "Epoch 5/10, Loss: 0.5592, Acc: 0.7013, Val Loss: 0.6367, Val Acc: 0.6617\n",
      "Epoch 6/10, Loss: 0.5235, Acc: 0.7388, Val Loss: 0.5813, Val Acc: 0.7065\n",
      "Epoch 7/10, Loss: 0.5243, Acc: 0.7338, Val Loss: 0.7844, Val Acc: 0.6119\n",
      "Epoch 8/10, Loss: 0.5057, Acc: 0.7525, Val Loss: 0.9460, Val Acc: 0.6269\n",
      "Epoch 9/10, Loss: 0.5030, Acc: 0.7425, Val Loss: 0.5460, Val Acc: 0.7164\n",
      "Epoch 10/10, Loss: 0.4755, Acc: 0.7800, Val Loss: 0.5426, Val Acc: 0.7562\n"
     ]
    }
   ],
   "source": [
    "num_epochs_aug = 10\n",
    "\n",
    "for epoch in range(num_epochs_aug):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader_aug:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset_aug)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # VALIDACIÓN (SIN augmentations)\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs_aug}, \"\n",
    "        f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c303348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6571219857504118)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses = np.array(history['val_loss'])\n",
    "\n",
    "val_losses_aug = val_losses[-10:]\n",
    "mean_val_loss_aug = np.mean(val_losses_aug)\n",
    "mean_val_loss_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8060b95",
   "metadata": {},
   "source": [
    "Question 6\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "0.08\n",
    "0.28\n",
    "0.68\n",
    "0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbeedab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.70646766, 0.6119403 , 0.62686567, 0.71641791, 0.75621891]),\n",
       " np.float64(0.6835820895522388))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accs = np.array(history['val_acc'])\n",
    "\n",
    "last_5_val_accs = val_accs[-5:]\n",
    "\n",
    "average_last_5 = np.mean(last_5_val_accs)\n",
    "\n",
    "last_5_val_accs, average_last_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
